{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# bigquery connection\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './My First Project-5abe6994fdf1.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(file)\n",
    "project_id = 'keen-bucksaw-273300'\n",
    "client = bigquery.Client(credentials= credentials,project=project_id)\n",
    "\n",
    "# Plotly mapbox public token\n",
    "mapbox_access_token = \"pk.eyJ1IjoicGxvdGx5bWFwYm94IiwiYSI6ImNqdnBvNDMyaTAxYzkzeW5ubWdpZ2VjbmMifQ.TXcBE-xg9BFdV2ocecc_7g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying downsampled data from bigquery database\n",
    "\n",
    "years = [2013, 2014, 2015, 2016, 2017, 2018]\n",
    "\n",
    "for year in years:\n",
    "    start = \"'\" + str(year) + \"-01-01'\"\n",
    "    end = \"'\" + str(year) + \"-12-31'\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n",
    "    WHERE rand() < 1/10\n",
    "    AND starttime between {start} and {end}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    query_job = client.query(query)\n",
    "    results = query_job.result() \n",
    "    df = results.to_dataframe()\n",
    "    df.to_csv(f'./data/initial/{str(year)}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigquery database has gap between 2016-10 and 2017-03, and stops at 2018-05\n",
    "# downloading remaining data from citibike aws\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "errors = []\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import requests\n",
    "\n",
    "url = \"https://s3.amazonaws.com/tripdata/\"\n",
    "\n",
    "page = requests.get(url)    \n",
    "data = page.text\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "links = []\n",
    "for link in soup.find_all('key'):\n",
    "    links.append(link.get_text())\n",
    "    \n",
    "# need to find less hideous way of selecting links:\n",
    "\n",
    "gap = links[41:47]\n",
    "for link in links[61:82]:\n",
    "    gap.append(link)\n",
    "\n",
    "for link in gap:\n",
    "    print(f'fetching {link}')\n",
    "    URL = f'https://s3.amazonaws.com/tripdata/{link}'\n",
    "    \n",
    "    url = urlopen(URL)\n",
    "    output = open('zipFile.zip', 'wb')    # note the flag:  \"wb\"        \n",
    "    output.write(url.read())\n",
    "    output.close()\n",
    "\n",
    "    zip_file = ZipFile('zipFile.zip')\n",
    "    dfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\n",
    "           for text_file in zip_file.infolist()\n",
    "           if text_file.filename.endswith('.csv')}\n",
    "    \n",
    "    try:\n",
    "        if 'csv' in link:\n",
    "            file = link.replace('.zip', '')\n",
    "        else:            \n",
    "            file = link.replace('zip', 'csv')\n",
    "        \n",
    "        print(f'downloading {file}')    \n",
    "        dfs[file].to_csv(f'./data/citi/{file}', index = False)\n",
    "    except:\n",
    "        errors.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/citi/201809-citibike-tripdata.csv', \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    i = next(reader)\n",
    "    \n",
    "columns = [i.replace(' ', '_') for i in i[1:]]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and combining citibike AWS data\n",
    "\n",
    "df_citi = pd.DataFrame()\n",
    "filelist = os.listdir('./data/citi')\n",
    "\n",
    "for file in filelist:\n",
    "    if file.endswith('.csv'):\n",
    "        \n",
    "        print(f'reading {file}')\n",
    "        \n",
    "        temp_df = pd.read_csv(f'./data/citi/{file}').drop(columns = {'Unnamed: 0'})\n",
    "                \n",
    "        temp_df.columns = columns\n",
    "        \n",
    "        df_citi = df_citi.append(temp_df.sample(frac = 0.1))\n",
    "\n",
    "df_citi.to_csv('./data/citi/combined.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for people going on bike rides\n",
    "\n",
    "query = \"\"\"\n",
    "with a as (\n",
    "\n",
    "    select start_station_id\n",
    "    , end_station_id\n",
    "    , start_station_latitude\n",
    "    , start_station_longitude\n",
    "    , end_station_latitude\n",
    "    , end_station_longitude\n",
    "    , tripduration\n",
    "    , bikeid\n",
    "    , starttime\n",
    "    , stoptime\n",
    "    , birth_year\n",
    "    , gender\n",
    "    FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n",
    "    where start_station_id is not null\n",
    "    and end_station_id is not null\n",
    "    and birth_year is not null  \n",
    "    \n",
    "), b as (\n",
    "\n",
    "    select start_station_id\n",
    "    , end_station_id\n",
    "    , tripduration\n",
    "    , bikeid\n",
    "    , starttime\n",
    "    , stoptime\n",
    "    , birth_year\n",
    "    , gender\n",
    "    FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n",
    "    where start_station_id is not null\n",
    "    and end_station_id is not null\n",
    "    and birth_year is not null\n",
    ")\n",
    "\n",
    "select a.start_station_id\n",
    ", a.end_station_id\n",
    ", a.start_station_latitude\n",
    ", a.start_station_longitude\n",
    ", a.end_station_latitude\n",
    ", a.end_station_longitude\n",
    ", a.starttime as a_start\n",
    ", b.starttime as b_start\n",
    ", a.stoptime as a_stop\n",
    ", b.stoptime as b_stop\n",
    ", a.tripduration as a_duration\n",
    ", b.tripduration as b_duration\n",
    ", a.birth_year as a_yob\n",
    ", a.gender as a_gender\n",
    ", b.birth_year as b_yob\n",
    ", b.gender as b_gender\n",
    "from a join b on a.start_station_id = b.start_station_id\n",
    "\t\tand a.end_station_id = b.end_station_id\n",
    "\t\tand a.bikeid <> b.bikeid\n",
    "        and a.starttime > b.starttime\n",
    "\t\tand timestamp_diff(timestamp(a.starttime), timestamp(b.starttime), second) <= 30 \n",
    "\t\tand abs(timestamp_diff(timestamp(a.stoptime), timestamp(b.stoptime), second)) <= 30  \n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "results = query_job.result() \n",
    "df = results.to_dataframe()\n",
    "df.to_csv('./data/initial/bike_rides.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for commuters\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "with a as(\n",
    "\n",
    "    select start_station_id\n",
    "    , start_station_latitude\n",
    "    , start_station_longitude\n",
    "    , end_station_id\n",
    "    , end_station_latitude\n",
    "    , end_station_longitude\n",
    "    , starttime\n",
    "    , stoptime\n",
    "    , tripduration\n",
    "    , birth_year\n",
    "    , gender\n",
    "    FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n",
    "    where start_station_id is not null\n",
    "    and end_station_id is not null\n",
    "    and birth_year is not null\n",
    "    and tripduration > 120\n",
    "), b as (\n",
    "\n",
    "    select start_station_id\n",
    "    , end_station_id\n",
    "    , starttime\n",
    "    , stoptime\n",
    "    , tripduration\n",
    "    , birth_year\n",
    "    , gender\n",
    "    FROM `bigquery-public-data.new_york_citibike.citibike_trips`\n",
    "    where start_station_id is not null\n",
    "    and end_station_id is not null\n",
    "    and birth_year is not null\n",
    "    and tripduration > 120\n",
    ")\n",
    "\n",
    "select a.start_station_id as home\n",
    ", a.start_station_latitude\n",
    ", a.start_station_longitude\n",
    ", a.end_station_id as work\n",
    ", a.end_station_latitude\n",
    ", a.end_station_longitude\n",
    ", a.starttime as depart_home\n",
    ", a.stoptime as arrive_work\n",
    ", a.tripduration as commute_in\n",
    ", b.starttime as depart_work\n",
    ", b.stoptime as arrive_home\n",
    ", b.tripduration as commute_out\n",
    "from a join b on a.start_station_id = b.end_station_id\n",
    "and a.end_station_id = b.start_station_id\n",
    "and timestamp_trunc(timestamp(a.starttime), day, 'UTC') = timestamp_trunc(timestamp(b.starttime), day, 'UTC')\n",
    "and a.starttime < b.starttime\n",
    "and a.birth_year = b.birth_year\n",
    "and a.gender = b.gender\n",
    "and a.start_station_id <> b.start_station_id\n",
    "and timestamp_diff(timestamp(b.starttime), timestamp(a.stoptime), hour) >= 6\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "results = query_job.result() \n",
    "df = results.to_dataframe()\n",
    "df.to_csv('./data/initial/commuters.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
